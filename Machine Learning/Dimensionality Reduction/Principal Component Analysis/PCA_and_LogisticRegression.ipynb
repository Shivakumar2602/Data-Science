{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA_and_LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMawlBHrxm78wUDC23JHdQx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GmFKhB33YtPA"},"source":["               ** PCA + Logistic Regression (MNIST)**\n","The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n","\n","Parameters\tNumber\n","Classes\t10\n","Samples per class\t~7000 samples per class\n","Samples total\t70000\n","Dimensionality\t784\n","Features\tintegers values from 0 to 255\n","The MNIST database of handwritten digits is available on the following website: MNIST Dataset\n","http://yann.lecun.com/exdb/mnist/\n","\n","Tutorial Link: https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n","\n","Github Link: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Sklearn/PCA/PCA_Image_Reconstruction_and_such.ipynb\n","\n","Sebastian Article link: https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html"]},{"cell_type":"markdown","metadata":{"id":"17730hyPrElB"},"source":["**Logistic Regression and PCA**"]},{"cell_type":"markdown","metadata":{"id":"80r1jO1gq549"},"source":["One of the most important applications of PCA is for speeding up machine learning algorithms. Using the IRIS dataset would be impractical here as the dataset only has 150 rows and only 4 feature columns. The MNIST database of handwritten digits is more suitable as it has 784 feature columns (784 dimensions), a training set of 60,000 examples, and a test set of 10,000 examples."]},{"cell_type":"markdown","metadata":{"id":"CRpR8OLUrQNF"},"source":["          **Download and Load the Data**\n","You can also add a data_home parameter to fetch_mldata to change where you download the data."]},{"cell_type":"code","metadata":{"id":"l1o5GoZelxm4"},"source":["from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DrlaU5aTrm0h"},"source":["The images that you downloaded are contained in mnist.data and has a shape of (70000, 784) meaning there are 70,000 images with 784 dimensions (784 features).\n","\n","The labels (the integers 0–9) are contained in mnist.target. The features are 784 dimensional (28 x 28 images) and the labels are simply numbers from 0–9."]},{"cell_type":"markdown","metadata":{"id":"R3UpuiR2rwpI"},"source":["        **Split Data into Training and Test Sets**\n","Typically the train test split is 80% training and 20% test. In this case, I chose 6/7th of the data to be training and 1/7th of the data to be in the test set."]},{"cell_type":"code","metadata":{"id":"SKen5zq1r3HV"},"source":["from sklearn.model_selection import train_test_split\n","\n","# test_size: what proportion of original data is used for test set\n","train_img, test_img, train_lbl, test_lbl = train_test_split( mnist.data, mnist.target, test_size=1/7.0, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nvf45_wJsFfl"},"source":["          **Standardize the Data**\n","The text in this paragraph is almost an exact copy of what was written earlier. PCA is effected by scale so you need to scale the features in the data before applying PCA. You can transform the data onto unit scale (mean = 0 and variance = 1) which is a requirement for the optimal performance of many machine learning algorithms. StandardScaler helps standardize the dataset’s features. Note you fit on the training set and transform on the training and test set. If you want to see the negative effect not scaling your data can have, scikit-learn has a section on the effects of not standardizing your data.\n","\n","**Importance of Feature Scaling**\n","\n","https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py"]},{"cell_type":"code","metadata":{"id":"CZWgbdMnswzR"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","# Fit on training set only.\n","scaler.fit(train_img)\n","\n","# Apply transform to both the training set and the test set.\n","train_img = scaler.transform(train_img)\n","test_img = scaler.transform(test_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vNqUUUPYs4rX"},"source":["**Import and Apply PCA**\n","Notice the code below has .95 for the number of components parameter. It means that scikit-learn choose the minimum number of principal components such that 95% of the variance is retained."]},{"cell_type":"code","metadata":{"id":"bTOzMBlms_Yy"},"source":["from sklearn.decomposition import PCA\n","\n","# Make an instance of the Model\n","pca = PCA(.95)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMDZw0I6tFHx","executionInfo":{"status":"ok","timestamp":1601413890093,"user_tz":300,"elapsed":14063,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"62629913-384f-484e-d283-40fa4e662cb1","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Fit PCA on training set. Note: you are fitting PCA on the training set only.\n","\n","pca.fit(train_img)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n","    svd_solver='auto', tol=0.0, whiten=False)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"t2ZLvekQtR-W"},"source":["Note: You can find out how many components PCA choose after fitting the model using pca.n_components_ . In this case, 95% of the variance amounts to 330 principal components."]},{"cell_type":"markdown","metadata":{"id":"RTtE5uI8tTO_"},"source":["**Apply the mapping (transform) to both the training set and the test set.**"]},{"cell_type":"code","metadata":{"id":"2TmeBuvFt0HW"},"source":["train_img = pca.transform(train_img)\n","test_img = pca.transform(test_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"diQLPE6ot3HD"},"source":["**Apply Logistic Regression to the Transformed Data**\n","\n","Step 1: Import the model you want to use\n","In sklearn, all machine learning models are implemented as Python classes"]},{"cell_type":"code","metadata":{"id":"742kRuHmt__4"},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-LVfdE3uHxI"},"source":["Step 2: Make an instance of the Model."]},{"cell_type":"code","metadata":{"id":"mk6sQg_XuECu"},"source":["# all parameters not specified are set to their defaults\n","# default solver is incredibly slow which is why it was changed to 'lbfgs'\n","\n","logisticRegr = LogisticRegression(max_iter=2000,solver = 'lbfgs')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hGLzcR7uuTHd"},"source":["Step 3: Training the model on the data, storing the information learned from the data\n","\n","Model is learning the relationship between digits and labels\n","\n","I was getting an error for code to increase the maximum no of iteration, I have the max_iter=2000 in above line of code"]},{"cell_type":"code","metadata":{"id":"pOxRYwmCuR1x","executionInfo":{"status":"ok","timestamp":1601414947376,"user_tz":300,"elapsed":140149,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"c202e404-3c68-4c52-81dd-a22089b75cdf","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["logisticRegr.fit(train_img, train_lbl)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"anu_5LG_w86k"},"source":["Step 4: Predict the labels of new data (new images)\n","\n","Uses the information the model learned during the model training process\n","\n","The code below predicts for one observation"]},{"cell_type":"code","metadata":{"id":"P558pJnBzEsQ","executionInfo":{"status":"ok","timestamp":1601415477600,"user_tz":300,"elapsed":831,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"5e7d2944-8fab-455b-a675-9282fed66b33","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Predict for One Observation (image)\n","logisticRegr.predict(test_img[0].reshape(1,-1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['0'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"-VXwz2nWzPvU","executionInfo":{"status":"ok","timestamp":1601415481492,"user_tz":300,"elapsed":765,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"0705a382-b059-41f6-aaa6-49b1091f5c8a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Predict for One Observation (image)\n","logisticRegr.predict(test_img[1].reshape(1,-1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['4'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"eMkzlkxNzUcT","executionInfo":{"status":"ok","timestamp":1601415510258,"user_tz":300,"elapsed":614,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"06d3c0bc-d61b-4ed9-f7ea-2eb973afce30","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#The code below predicts for multiple observations at once\n","\n","# Predict for One Observation (image)\n","logisticRegr.predict(test_img[0:10])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['0', '4', '1', '2', '4', '7', '7', '1', '1', '7'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"VAYl_zy72aIA"},"source":["Predictions=logisticRegr.predict(test_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4pa7JvSzbXe"},"source":["Measuring Model Performance\n","\n","While accuracy is not always the best metric for machine learning algorithms (precision, recall, F1 Score, ROC Curve, etc would be better), it is used here for simplicity.\n","\n","ROC: https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0\n","\n","Accuracy is defined as:\n","(fraction of correct predictions): correct predictions / total number of data points"]},{"cell_type":"code","metadata":{"id":"mSX9ssEXzdDr","executionInfo":{"status":"ok","timestamp":1601415544473,"user_tz":300,"elapsed":844,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"5ec277e2-99ad-4c4d-e7c9-f8b66d354228","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["logisticRegr.score(test_img, test_lbl)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9184"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"2nfhroEp1pbf"},"source":["Since Logistic regression is not same as Linear regression , predicting just accuracy will mislead. \n","** Confusion Matrix** is one way to evaluate the performance of your model. Checking the values of True Positives, False Negatives ( Type II Error) are really important.\n","\n","** ROC Curve** Receiver Operating Characteristic(ROC) summarizes the model’s performance by evaluating the trade offs between true positive rate (sensitivity) and false positive rate(1- specificity)"]},{"cell_type":"markdown","metadata":{"id":"U22ugFQd2_Ir"},"source":["**Confusion Matrix**\n","\n","A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. In this section, I am just showing two python packages (Seaborn and Matplotlib) for making confusion matrices more understandable and visually appealing.\n","\n","https://intellipaat.com/blog/confusion-matrix-python/"]},{"cell_type":"code","metadata":{"id":"eVC9G6UV1s5X","executionInfo":{"status":"ok","timestamp":1601416733342,"user_tz":300,"elapsed":840,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"e63b2ba4-817c-424f-8cb7-a94158706905","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["from sklearn import metrics\n","\n","cm = metrics.confusion_matrix(test_lbl, Predictions)\n","print(cm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 965    0    2    2    1   10    9    1    5    1]\n"," [   0 1105   13    1    1    6    0    4    9    2]\n"," [   3   15  929   19   13    4   14   12   27    4]\n"," [   1    7   39  889    1   29    1   13   20   13]\n"," [   1    3    8    0  901    0   11    7    4   27]\n"," [   7    2    9   29    7  759   15    3   27    5]\n"," [   8    2    9    0   13   14  935    1    5    2]\n"," [   4    4   16    2   11    5    0  977    6   39]\n"," [   3   19    8   20    7   25    7    2  858   14]\n"," [   4    4    3   11   30   10    1   34    6  866]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S3-9fAse56c5","executionInfo":{"status":"ok","timestamp":1601417285274,"user_tz":300,"elapsed":771,"user":{"displayName":"Shiva kumar Ramavath","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiYRpt3IW9-bN_N32tPhfgKdgzds55Fy2ns03cAg=s64","userId":"05600410476591999105"}},"outputId":"a215f40c-6cd9-4a4c-8146-e69c163e6131","colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["classification_report=metrics.classification_report(test_lbl, Predictions)\n","print(classification_report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.97      0.97       996\n","           1       0.95      0.97      0.96      1141\n","           2       0.90      0.89      0.89      1040\n","           3       0.91      0.88      0.90      1013\n","           4       0.91      0.94      0.93       962\n","           5       0.88      0.88      0.88       863\n","           6       0.94      0.95      0.94       989\n","           7       0.93      0.92      0.92      1064\n","           8       0.89      0.89      0.89       963\n","           9       0.89      0.89      0.89       969\n","\n","    accuracy                           0.92     10000\n","   macro avg       0.92      0.92      0.92     10000\n","weighted avg       0.92      0.92      0.92     10000\n","\n"],"name":"stdout"}]}]}